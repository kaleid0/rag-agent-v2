[project]
name = "RAG-Agent-v2"
version = "0.1.0"
description = "RAG - Agent"
authors = [{ name = "Kyleidoscopist", email = "1053503073@qq.com" }]
requires-python = ">=3.11"
dependencies = [
    "uvicorn>=0.38.0",
    "fastapi>=0.124.0",
    "beanie>=2.0.1",
    "motor>=3.7.1",
    "chromadb>=1.3.5",
    "openai>=2.9.0",
    "langchain-core>=1.1.1",
    "langchain-community>=0.4.1",
    "docling>=2.64.0",
    "python-multipart>=0.0.20",
    "streamlit>=1.52.1",
]

[build-system]
requires = ["setuptools>=42", "wheel"]
build-backend = "setuptools.build_meta"

[tool.mongo]
uri = "mongodb://localhost:27017"
db_name = "rag_agent_v2_database"


[tool.chroma]
persist_directory = "data/chroma_db"
# 可选：如需远程 ChromaDB 服务，取消注释并填写
# host = "localhost"
# port = 8000
# settings = "{}"  # 如有特殊设置，可填写 JSON 字符串

[tool.dialog]
llm_provider = "bailian" # deepseek, bailian
llm_model = "qwen-plus" # qwen-plus, deepseek-chat


[tool.rag]
# 检索器配置
retriever_type = "hybrid" # vector, sparse, hybrid
# 上传配置
file_storage_dir = "data/stored_files"
max_file_size_mb = 10                  # MB
# 解析配置
markdown_storage_dir = "data/markdown_files"
chunk_dir = "data/chunked_files"
chunk_size = 300
chunk_overlap = 50
split_method = "hierarchical"                # character, recursive, hierarchical
llm_provider = "bailian" # deepseek, bailian
llm_model = "qwen-plus" # qwen-plus, deepseek-chat
embedding_provider = "bailian"
embedding_model = "text-embedding-ada-002"

# 检索配置
top_k = 5
query_rewrite = true
query_route = true
rerank = true
context_retrieve = true
# retrievel_method = ["bm25", "chroma"] # bm25, chroma

[tool.rag.docling]
do_picture_description = false
do_ocr = false
do_table_structure = true
do_cell_matching = true
# accelerator_options = 


[tool.memory]
# rag 配置
split_method = "character"        # character, recursive, hierarchical
max_chunk_size = 300
retriever_type = "vector"
top_k = 5
min_similarity_score = 0.75
chunk_dir = "data/chunked_memory"
