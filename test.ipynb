{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fdf9871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"jsonå­—ç¬¦ä¸²\": \"{\\\\\\\"name\\\\\\\": \\\\\\\"å¼ ä¸‰\\\\\\\", \\\\\\\"age\\\\\\\": 30, \\\\\\\"city\\\\\\\": \\\\\\\"åŒ—äº¬\\\\\\\"}\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key=\"sk-xxx\"\n",
    "    api_key=os.getenv(\"BAILIAN_API_KEY\"),\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    # æ¨¡å‹åˆ—è¡¨ï¼šhttps://help.aliyun.com/zh/model-studio/getting-started/models\n",
    "    model=\"qwen-plus\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ä»¥jsonæ ¼å¼è¾“å‡ºä¸€ä¸ªjsonå­—ç¬¦ä¸²\"},\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef35b250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"jsonå­—ç¬¦ä¸²\": \"{\\\\\\\"name\\\\\\\": \\\\\\\"å¼ ä¸‰\\\\\\\", \\\\\\\"age\\\\\\\": 30, \\\\\\\"city\\\\\\\": \\\\\\\"åŒ—äº¬\\\\\\\"}\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a34cbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do_picture_description\n",
      "do_ocr\n",
      "do_table_structure\n",
      "do_cell_matching\n"
     ]
    }
   ],
   "source": [
    "from config import rag_cfg\n",
    "\n",
    "for item in rag_cfg[\"docling\"]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a80cf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Role>\n",
      "You are a query routing assistant that determines which collections are most relevant to the user's question.\n",
      "</Role>\n",
      "<Instructions>\n",
      "1. Carefully read user's Question.\n",
      "2. For each collection in **Collections**, assign a relevance score from 0 to 5:\n",
      "   - 0 = Completely irrelevant\n",
      "   - 1 = Very low relevance\n",
      "   - 2 = Low relevance\n",
      "   - 3 = Moderate relevance\n",
      "   - 4 = High relevance\n",
      "   - 5 = Very high relevance\n",
      "3. Base your scoring only on the semantic meaning of the question and the collection name.\n",
      "4. Output your answer strictly in **valid JSON format**, where:\n",
      "   - Keys are the collection names (exactly as given)\n",
      "   - Values are the relevance scores (integers from 0 to 5)\n",
      "</Instructions>\n",
      "<Example>\n",
      "**Input Question**:\n",
      "å·ç§¯ç½‘ç»œå’Œ Transformer ç½‘ç»œçš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ\n",
      "\n",
      "**Collections**:\n",
      "\n",
      "{{\n",
      "   {{\n",
      "      \"collection\": \"Resnet\",\n",
      "      \"keywords\": [...],\n",
      "   }},\n",
      "   {{\n",
      "      \"collection\": \"ViT\",\n",
      "      \"keywords\": [...]\n",
      "   }},\n",
      "   {{\n",
      "      \"collection\": \"Knowledge Distillation\",\n",
      "      \"keywords\": [...]\n",
      "   }}\n",
      "}}\n",
      "\n",
      "**Output**:\n",
      "\n",
      "```json\n",
      "{{\n",
      "  \"Resnet\": 5,\n",
      "  \"ViT\": 5,\n",
      "  \"Knowledge Distillation\": 0\n",
      "}}\n",
      "```\n",
      "</Example>\n",
      "<Collections>\n",
      "{collections}\n",
      "</Collections>\n",
      "<User's_Question>\n",
      "{question}\n",
      "</User's_Question>\n"
     ]
    }
   ],
   "source": [
    "from src.prompt import get_prompt\n",
    "\n",
    "prompt = get_prompt(\"query_route\", \"rag\")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b44ed242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Header 1': 'system', 'content': 'ç³»ç»Ÿæ¶ˆæ¯â€¦â€¦'}\n",
      "{'Header 1': 'user', 'content': 'ç”¨æˆ·æ¶ˆæ¯éå¸¸é•¿ï¼Œéå¸¸'}\n",
      "{'Header 1': 'user', 'content': 'é•¿ï¼Œéå¸¸é•¿â€¦â€¦ï¼ˆ>3'}\n",
      "{'Header 1': 'user', 'content': '00ï¼‰'}\n",
      "{'Header 1': 'assistant', 'content': 'åŠ©æ‰‹å›å¤'}\n"
     ]
    }
   ],
   "source": [
    "def split_messages(messages: list[dict[str, str]], max_len: int = 2):\n",
    "    result = []\n",
    "\n",
    "    for msg in messages:\n",
    "        role = msg.get(\"role\", \"\")\n",
    "        content = msg.get(\"content\", \"\")\n",
    "\n",
    "        # æŒ‰ max_len åˆ‡åˆ† content\n",
    "        parts = [content[i : i + max_len] for i in range(0, len(content), max_len)]\n",
    "\n",
    "        # ä¸ºæ¯æ®µåˆ›å»ºä¸€æ¡æ–°æ¶ˆæ¯\n",
    "        for part in parts:\n",
    "            result.append({\"Header 1\": role, \"content\": part})\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"ç³»ç»Ÿæ¶ˆæ¯â€¦â€¦\"},\n",
    "    {\"role\": \"user\", \"content\": \"ç”¨æˆ·æ¶ˆæ¯éå¸¸é•¿ï¼Œéå¸¸é•¿ï¼Œéå¸¸é•¿â€¦â€¦ï¼ˆ>300ï¼‰\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"åŠ©æ‰‹å›å¤\"},\n",
    "]\n",
    "\n",
    "processed = split_messages(messages, max_len=10)\n",
    "\n",
    "for item in processed:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a57a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"text1\": 1, \"text2\": 2, \"text3\": 3, \"text4\": 4, \"text5\": 5}\n",
    "a = list(map(int, d.values()))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import rag_cfg\n",
    "\n",
    "a = rag_cfg.get(\"query_route\")\n",
    "\n",
    "if a:\n",
    "    print(\"Query route is set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c40c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG.retrieve_pipeline.utils import extract_title_from_markdown\n",
    "\n",
    "text = \"\"\"\n",
    "ä¸‹é¢ç”¨**ç›´è§‚ç‰ˆ â†’ æŠ€æœ¯ç‰ˆ â†’ æ•°å­¦ç‰ˆ â†’ ç¤ºä¾‹æµç¨‹å›¾**å››å±‚æ·±åº¦ï¼Œç³»ç»Ÿåœ°ç»™ä½ è®²æ¸…æ¥š **RLHFï¼ˆReinforcement Learning from Human Feedbackï¼‰åŸç†**ã€‚\n",
    "ï¼ˆè€ƒè™‘åˆ°ä½ æœ¬èº«åš KDã€å…ƒå­¦ä¹ æ°´å°ç­‰ï¼Œæˆ‘ä¼šå°½é‡ç»™å‡ºâ€œæœºåˆ¶çº§â€è§£é‡Šã€‚ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒŸ ä¸€ã€ç›´è§‚ç‰ˆï¼šRLHF åˆ°åº•åœ¨åšä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "RLHFçš„ä»»åŠ¡æ˜¯ï¼š\n",
    "\n",
    "> **è®©æ¨¡å‹ä¸ä»…â€œä¼šå›ç­”â€ï¼ˆSFTï¼‰ï¼Œè¿˜â€œå›ç­”å¾—æ›´æ¥è¿‘äººç±»åå¥½â€ã€‚**\n",
    "\n",
    "å®ƒæ€ä¹ˆåšåˆ°ï¼Ÿ\n",
    "\n",
    "1. **äººç±»ç»™æ¨¡å‹è¾“å‡ºæ‰“åˆ†/æ’åº â†’ å¾—åˆ°åå¥½æ•°æ®**\n",
    "2. **è®­ç»ƒä¸€ä¸ªå¥–åŠ±æ¨¡å‹ï¼ˆReward Modelï¼‰æ¥æ¨¡ä»¿è¿™äº›åå¥½**\n",
    "3. **ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œè®©å¤§æ¨¡å‹åœ¨ç”Ÿæˆæ—¶æœ€å¤§åŒ–å¥–åŠ±æ¨¡å‹çš„å¾—åˆ†ï¼ŒåŒæ—¶ä¿æŒè¯­è¨€æµç•…**\n",
    "\n",
    "å®ƒçš„æ ¸å¿ƒæ€æƒ³ï¼š\n",
    "\n",
    "> **ç”¨ RM å½“ä½œâ€œå¯å¾®å¥–åŠ±å‡½æ•°â€ï¼Œç”¨ RL è®©ç­–ç•¥æ¨¡å‹ç¬¦åˆè¿™ä¸ªå¥–åŠ±å‡½æ•°ã€‚**\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒŸ äºŒã€æŠ€æœ¯ç‰ˆï¼šRLHF ä¸‰é˜¶æ®µåŸç†ï¼ˆChatGPT ä½¿ç”¨çš„æµç¨‹ï¼‰\n",
    "\n",
    "## âœ”ï¸ **é˜¶æ®µ 1ï¼šSFTï¼ˆç›‘ç£å¾®è°ƒï¼‰**\n",
    "\n",
    "ç”¨é«˜è´¨é‡ `(prompt, answer)` æ•°æ®è®­ç»ƒå‡ºä¸€ä¸ªåˆå§‹æ¨¡å‹ Ï€â‚€ã€‚\n",
    "å®ƒåªæ˜¯â€œèƒ½å›ç­”é—®é¢˜â€ï¼Œä½†ä¸æ‡‚å¯¹é½ï¼Œä¸æ‡‚å®‰å…¨è§„èŒƒã€‚\n",
    "\n",
    "**è¾“å‡ºç»“æœï¼šSFT æ¨¡å‹ = å¥½å­¦ç”Ÿï¼Œä½†ä¸æ‡‚â€œè€å¸ˆå–œæ¬¢ä»€ä¹ˆâ€ã€‚**\n",
    "\n",
    "---\n",
    "\n",
    "## âœ”ï¸ **é˜¶æ®µ 2ï¼šå¥–åŠ±æ¨¡å‹ RMï¼ˆPreference Modelï¼‰**\n",
    "\n",
    "è¾“å…¥ï¼šæ¨¡å‹ç”Ÿæˆçš„ä¸¤ä¸ªå›ç­” `y_pos` å’Œ `y_neg`\n",
    "æ ‡ç­¾ï¼šäººç±»è¯´ â€œy_pos æ¯” y_neg æ›´å¥½â€\n",
    "\n",
    "è®­ç»ƒç›®æ ‡ï¼š\n",
    "\n",
    "> è®© RM è¾“å‡ºï¼š\n",
    "> reward(y_pos) > reward(y_neg)\n",
    "\n",
    "å…·ä½“å½¢å¼ï¼š\n",
    "\n",
    "[\n",
    "\\mathcal{L}_{RM} = - \\log\\sigma(r(y^{+}) - r(y^{-}))\n",
    "]\n",
    "\n",
    "è®­ç»ƒå‡ºçš„ RM æ˜¯ä¸€ä¸ª **è¯„åˆ†å™¨**ï¼Œå¯ä»¥å¯¹ä»»æ„å›ç­”ç»™åˆ†ã€‚\n",
    "\n",
    "**è¾“å‡ºç»“æœï¼šå¥–åŠ±æ¨¡å‹ RM = æ¨¡ä»¿äººç±»åå¥½çš„è¯„åˆ†ç³»ç»Ÿã€‚**\n",
    "\n",
    "---\n",
    "\n",
    "## âœ”ï¸ **é˜¶æ®µ 3ï¼šå¼ºåŒ–å­¦ä¹ ï¼ˆPPOï¼‰ä¼˜åŒ–ç­–ç•¥æ¨¡å‹ RLHF-PPO**\n",
    "\n",
    "ç°åœ¨æœ‰ä¸¤ä¸ªæ¨¡å‹ï¼š\n",
    "\n",
    "* **ç­–ç•¥æ¨¡å‹ Ï€**ï¼ˆä½ æœ€ç»ˆè¦çš„ LLMï¼‰\n",
    "* **å¥–åŠ±æ¨¡å‹ r**ï¼ˆä½ è®©å®ƒæˆä¸ºâ€œè€å¸ˆâ€ï¼‰\n",
    "\n",
    "ç›®æ ‡ï¼š\n",
    "\n",
    "> **è®©ç­–ç•¥æ¨¡å‹ç”Ÿæˆçš„ç­”æ¡ˆè·å¾—é«˜å¥–åŠ±åˆ†æ•° r(answer)ï¼Œä½†åˆä¸èƒ½åç¦»åŸæœ¬è¯­è¨€èƒ½åŠ›å¤ªè¿œã€‚**\n",
    "\n",
    "æ‰€ä»¥ç›®æ ‡å‡½æ•°æ˜¯ï¼š\n",
    "\n",
    "[\n",
    "\\max_{\\pi} \\ \\mathbb{E}[ r(y) ] - \\beta \\cdot KL(\\pi ,||, \\pi_0)\n",
    "]\n",
    "\n",
    "å…¶ä¸­ KL çº¦æŸæ˜¯ä¸ºäº†ï¼š\n",
    "\n",
    "* é˜²æ­¢ reward hacking\n",
    "* ä¿æŒè¯­è¨€è´¨é‡\n",
    "* é¿å…æ¨¡å‹åç¦»è¿‡å¤´ï¼ˆå´©åï¼‰\n",
    "\n",
    "### â­ PPO çš„ä½œç”¨\n",
    "\n",
    "PPO æ˜¯ä¸€ç§â€œç¨³å®šå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å™¨â€ï¼Œå®ƒçš„æŠ€å·§ï¼š\n",
    "\n",
    "* é™åˆ¶æ–°æ—§ç­–ç•¥æ¦‚ç‡æ¯” `ratio` ä¸è¦å˜åŒ–å¤ªå¤§ï¼ˆclip æŠ€æœ¯ï¼‰\n",
    "* é¿å…è®­ç»ƒå‘æ•£\n",
    "* è®© KL ä¸ä¼šçªç„¶çˆ†ç‚¸\n",
    "\n",
    "ç®€åŒ–ç‰ˆæœ¬çš„ PPO ç›®æ ‡ï¼š\n",
    "\n",
    "[\n",
    "\\mathcal{L}_{PPO} = \\mathbb{E}\\left[\\min( ratio \\cdot A, \\ clip(ratio,1-\\epsilon,1+\\epsilon) \\cdot A )\\right]\n",
    "]\n",
    "\n",
    "å…¶ä¸­ advantage A ç”¨ RM ç®—ï¼š\n",
    "\n",
    "[\n",
    "A = r(y) - \\beta KL(\\pi||\\pi_0)\n",
    "]\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒŸ ä¸‰ã€æ•°å­¦åŸç†ï¼ˆæ ¸å¿ƒæ¦‚å¿µç”¨ä¸€å¥è¯æ€»ç»“ï¼‰\n",
    "\n",
    "| ç»„ä»¶           | æ•°å­¦æœ¬è´¨                                                  | ç”¨ä¸€å¥è¯è®²            |\n",
    "| ------------ | ----------------------------------------------------- | ---------------- |\n",
    "| **å¥–åŠ±æ¨¡å‹ RM**  | pairwise Bradley-Terry / logistic preference learning | å­¦â€œäººç±»æ›´å–œæ¬¢å“ªä¸€ä¸ªå›ç­”â€    |\n",
    "| **ç­–ç•¥ä¼˜åŒ– PPO** | KL-regularized policy gradient                        | â€œè®©æ¨¡å‹è¿½æ±‚é«˜åˆ†ä½†ä¸èƒ½åç¦»å¤ªå¤šâ€ |\n",
    "| **KL é¡¹**     | è½¯çº¦æŸé˜²é€€åŒ–                                                | ä¿æŒè¯­è¨€è´¨é‡ç¨³å®š         |\n",
    "| **RLHF æ•´ä½“**  | KL-æ­£åˆ™åŒ–çš„æœ€å¤§æœŸæœ›å¥–åŠ±                                         | æœ¬è´¨æ˜¯ä¼˜åŒ–â€œå¥–åŠ± + ç¨³å®šæ€§â€  |\n",
    "\n",
    "æ ¸å¿ƒä¼˜åŒ–é—®é¢˜ï¼š\n",
    "\n",
    "[\n",
    "\\pi^* = \\arg\\max_\\pi \\ \\mathbb{E}_{y\\sim\\pi}[r(y)] - \\beta KL(\\pi||\\pi_0)\n",
    "]\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒŸ å››ã€RLHF çš„ä¼˜åŠ¿ä¸é—®é¢˜\n",
    "\n",
    "## ğŸ‘ ä¼˜åŠ¿\n",
    "\n",
    "* å¼ºå¤§çš„å¯æ§æ€§\n",
    "* èƒ½å®ç°â€œå®‰å…¨â€ã€â€œç¤¼è²Œâ€ã€â€œæ‹’ç­”â€ç­‰è¡Œä¸º\n",
    "* èƒ½å­¦åˆ°äººç±»çš„åå¥½ï¼Œè€Œä¸æ˜¯æ­»è®°ç¡¬èƒŒç­”æ¡ˆ\n",
    "\n",
    "## ğŸ‘ é—®é¢˜ï¼ˆDPO å°±æ˜¯ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼‰\n",
    "\n",
    "* PPO éš¾è®­ç»ƒ\n",
    "* RM ä¼šâ€œå¥–åŠ±ä½œå¼Šâ€ï¼ˆreward hackingï¼‰\n",
    "* è®­ç»ƒæˆæœ¬é«˜ï¼ˆå¤§æ‰¹é‡ç”Ÿæˆ + RLï¼‰\n",
    "* ä¸ç¨³å®šï¼ˆKL æ§åˆ¶å¾ˆæ•æ„Ÿï¼‰\n",
    "\n",
    "DPO å°±æ˜¯åœ¨æ•°å­¦ä¸Šé‡æ–°æ¨å¯¼ RLHF çš„ç›®æ ‡ï¼Œä½¿å¾—ï¼š\n",
    "\n",
    "* ä¸éœ€è¦ RM\n",
    "* ä¸éœ€è¦ PPO\n",
    "* ç›´æ¥æœ€å¤§åŒ–åå¥½å¯¹æ•°ä¼¼ç„¶\n",
    "* æ›´ç¨³å®š\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸŒŸ äº”ã€RLHF æ•´ä½“æµç¨‹å›¾ï¼ˆè¶…æ¸…æ™°ï¼‰\n",
    "\n",
    "```\n",
    "             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "             â”‚    Stage 1: SFT ç›‘ç£å¾®è°ƒ         â”‚\n",
    "             â”‚   ç”¨äººå·¥å†™çš„å¥½ç­”æ¡ˆè®­ç»ƒ Ï€0        â”‚\n",
    "             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â”‚\n",
    "                            â–¼\n",
    "             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "             â”‚  Stage 2: å¥–åŠ±æ¨¡å‹ RM             â”‚\n",
    "             â”‚  è¾“å…¥ï¼šäººç±»åå¥½(ä¼˜ vs åŠ£)         â”‚\n",
    "             â”‚  å­¦ä¹ ï¼šr(y+) > r(y-)              â”‚\n",
    "             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â”‚\n",
    "                            â–¼\n",
    "             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "             â”‚  Stage 3: RLHF-PPO å¼ºåŒ–å­¦ä¹        â”‚\n",
    "             â”‚  ç­–ç•¥æ¨¡å‹ Ï€ ç”Ÿæˆç­”æ¡ˆ              â”‚\n",
    "             â”‚  RM æ‰“åˆ† â†’ Advantage             â”‚\n",
    "             â”‚  PPO æ›´æ–° Ï€ï¼Œä¿æŒ KL ç¨³å®š        â”‚\n",
    "             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                            â”‚\n",
    "                            â–¼\n",
    "                      ã€Œæœ€ç»ˆæ¨¡å‹ Ï€*ã€\n",
    "            = æ›´ç¬¦åˆäººç±»åå¥½çš„å¤§è¯­è¨€æ¨¡å‹\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘è¿˜èƒ½ç»§ç»­è®²ï¼š\n",
    "\n",
    "âœ… RLHF vs DPO æ•°å­¦æ¨å¯¼å¯¹æ¯”\n",
    "âœ… RM çš„å…·ä½“ç½‘ç»œç»“æ„ï¼ˆGPT decoder head + scalar headï¼‰\n",
    "âœ… PPO åœ¨ LLM ä¸­çš„ trickï¼ˆKL æ§åˆ¶ã€length normã€reward shapingï¼‰\n",
    "âœ… RLHF åœ¨è’¸é¦æ°´å°é¡¹ç›®ä¸­çš„ä½œç”¨\n",
    "ï¼ˆå°¤å…¶æ˜¯ä½ åšçš„å…ƒå­¦ä¹ è’¸é¦ï¼Œæ˜¯å¯ä»¥å’Œ RLHF çš„ KL æ­£åˆ™äº§ç”Ÿç±»æ¯”çš„ï¼‰\n",
    "\n",
    "ä½ æƒ³ç»§ç»­å“ªä¸ªéƒ¨åˆ†ï¼Ÿ\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "title = extract_title_from_markdown(text)\n",
    "for line in title:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f92e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "\n",
    "from src.llm.factory import get_llm\n",
    "from src.llm.base import add_user_message\n",
    "\n",
    "llm = get_llm(llm_provider=\"deepseek\", model=\"deepseek-chat\")\n",
    "\n",
    "messages = []\n",
    "add_user_message(messages, prompt)\n",
    "response = llm.chat(messages, format=\"json\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = json.loads(response)\n",
    "print(data.get(\"false\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac49fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = \"\"\"\n",
    "{\n",
    "    \"false\": \"No title found\",\n",
    "}\n",
    "\"\"\"\n",
    "data = json.loads(json_str)\n",
    "print(data.get(\"false\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-agent-v2 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
